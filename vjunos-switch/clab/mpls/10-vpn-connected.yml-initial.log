[WARNING]: Invalid characters were found in group names but not replaced, use
-vvvv to see details
[WARNING]: Could not match supplied host pattern, ignoring: unprovisioned

PLAY [Deploy initial device configuration] *************************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [pe2]
ok: [p1]
ok: [p2]
ok: [dut]
ok: [h1]
ok: [h3]
ok: [h2]
ok: [h4]

TASK [Find device readiness script] ********************************************
ok: [pe2]
ok: [p1]
ok: [p2]
ok: [dut]
ok: [h1]
ok: [h3]
ok: [h2]
ok: [h4]

TASK [Wait for device to become ready] *****************************************
skipping: [pe2]
skipping: [p1]
skipping: [p2]
skipping: [h1]
skipping: [h2]
skipping: [h3]
skipping: [h4]
included: /home/pipi/net101/tools/netsim/ansible/tasks/readiness-check/vjunos-switch-clab.yml for dut

TASK [Wait for SSH server] *****************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/readiness-check/vm-clab-ssh-check.yml for dut

TASK [Execute local ssh command to check vjunos-switch readiness] **************
FAILED - RETRYING: [dut -> localhost]: Execute local ssh command to check vjunos-switch readiness (40 retries left).
FAILED - RETRYING: [dut -> localhost]: Execute local ssh command to check vjunos-switch readiness (39 retries left).
changed: [dut -> localhost]

TASK [Confirm dut SSH server works] ********************************************
ok: [dut] => 
  msg: Node dut is ready.

TASK [Wait for ge-0/0/0 interface] *********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/readiness-check/vjunos-switch.yml for dut

TASK [Wait for ge-0/0/0 to appear] *********************************************
ok: [dut]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, pe2, p1, p2, h1, h2, h3, h4

TASK [Figure out whether to deploy the module initial on current device] *******
ok: [pe2]
ok: [p1]
ok: [dut]
ok: [p2]
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]

TASK [Find configuration template for initial] *********************************
ok: [pe2]
ok: [p1]
ok: [dut]
ok: [p2]
ok: [h2]
ok: [h1]
ok: [h4]
ok: [h3]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [h2] => 
  msg: |-
    initial configuration for h2
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.1.2/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.1.2/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.1.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.1.6
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.1.6
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.1.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.1.6
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.1.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.1.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.1.6
    #
    # Print the final routing table
    ip route
ok: [dut] => 
  msg: |-
    initial configuration for dut
    =========================================
    system {
      host-name dut
        static-host-mapping {
            pe2 inet 10.0.0.6;
            p1 inet 10.0.0.7;
            p2 inet 10.0.0.8;
            h1 inet 172.16.0.1;
            h2 inet 172.16.1.2;
            h3 inet 172.16.2.3;
            h4 inet 172.16.3.4;
        }
    }
  
  
  
  
  
  
  
  
    policy-options {
      community tg_65000_1 members target:65000:1;
      community tg_65000_2 members target:65000:2;
    }
  
  
  
    policy-options {
      policy-statement vrf-t1-export {
        term 1 {
          then {
            community add tg_65000_1;
            accept;
          }
        }
      }
  
  
  
      policy-statement vrf-t1-import {
        term 1 {
          from community [ tg_65000_1 ];
          then accept;
        }
        term default {
          then reject;
        }
      }
      policy-statement vrf-t2-export {
        term 1 {
          then {
            community add tg_65000_2;
            accept;
          }
        }
      }
  
  
  
      policy-statement vrf-t2-import {
        term 1 {
          from community [ tg_65000_2 ];
          then accept;
        }
        term default {
          then reject;
        }
      }
    }
  
    routing-instances {
  
      t1 {
        instance-type vrf;
        route-distinguisher 65000:1;
  
        vrf-import vrf-t1-import;
        vrf-export vrf-t1-export;
  
        routing-options {
          auto-export;
        }
  
        interface ge-0/0/1.0;
  
      }
  
  
      t2 {
        instance-type vrf;
        route-distinguisher 65000:2;
  
        vrf-import vrf-t2-import;
        vrf-export vrf-t2-export;
  
        routing-options {
          auto-export;
        }
  
        interface ge-0/0/2.0;
  
      }
  
    }
    interfaces {
      ge-0/0/0 {
        mtu 1514;
      }
      ge-0/0/1 {
        mtu 1514;
      }
      ge-0/0/2 {
        mtu 1514;
      }
  
      lo0.0 {
  
          family inet {
            address 10.0.0.5/32;
          }
  
      }
      ge-0/0/0.0 {
        description "dut -> p1";
  
          family inet {
            address 10.1.0.1/30;
          }
  
      }
      ge-0/0/1.0 {
        description "dut -> h1 [stub]";
  
          family inet {
            address 172.16.0.5/24;
          }
  
      }
      ge-0/0/2.0 {
        description "dut -> h3 [stub]";
  
          family inet {
            address 172.16.2.5/24;
          }
  
      }
    }
    protocols {
      lldp {
        interface fxp0 {
          disable;
        }
        interface all;
      }
    }
ok: [pe2] => 
  msg: |-
    initial configuration for pe2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "10.0.0.5 10.1.0.1 dut" >>/tmp/hosts
    echo "172.16.0.5 dut-t1" >>/tmp/hosts
    echo "172.16.2.5 dut-t2" >>/tmp/hosts
    echo "172.16.0.1 h1" >>/tmp/hosts
    echo "172.16.1.2 h2" >>/tmp/hosts
    echo "172.16.2.3 h3" >>/tmp/hosts
    echo "172.16.3.4 h4" >>/tmp/hosts
    echo "10.0.0.7 10.1.0.2 10.1.0.5 p1" >>/tmp/hosts
    echo "10.0.0.8 10.1.0.6 10.1.0.9 p2" >>/tmp/hosts
    echo "10.0.0.6 10.1.0.10 pe2" >>/tmp/hosts
    echo "172.16.1.6 pe2-t1" >>/tmp/hosts
    echo "172.16.3.6 pe2-t2" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth2.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth3.disable_ipv6=1
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    ip link set eth2 mtu 1500
    ip link set eth3 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname pe2
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.6/32
    !
    interface eth1
     no shutdown
     description pe2 -> p2
     ip address 10.1.0.10/30
    !
    interface eth2
     no shutdown
     description pe2 -> h2 [stub]
     ip address 172.16.1.6/24
    !
    interface eth3
     no shutdown
     description pe2 -> h4 [stub]
     ip address 172.16.3.6/24
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [h1] => 
  msg: |-
    initial configuration for h1
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.0.1/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.0.1/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.0.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.0.5
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.0.5
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.0.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.0.5
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.0.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.0.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.0.5
    #
    # Print the final routing table
    ip route
ok: [p1] => 
  msg: |-
    initial configuration for p1
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "10.0.0.5 10.1.0.1 dut" >>/tmp/hosts
    echo "172.16.0.5 dut-t1" >>/tmp/hosts
    echo "172.16.2.5 dut-t2" >>/tmp/hosts
    echo "172.16.0.1 h1" >>/tmp/hosts
    echo "172.16.1.2 h2" >>/tmp/hosts
    echo "172.16.2.3 h3" >>/tmp/hosts
    echo "172.16.3.4 h4" >>/tmp/hosts
    echo "10.0.0.7 10.1.0.2 10.1.0.5 p1" >>/tmp/hosts
    echo "10.0.0.8 10.1.0.6 10.1.0.9 p2" >>/tmp/hosts
    echo "10.0.0.6 10.1.0.10 pe2" >>/tmp/hosts
    echo "172.16.1.6 pe2-t1" >>/tmp/hosts
    echo "172.16.3.6 pe2-t2" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth2.disable_ipv6=1
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    ip link set eth2 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname p1
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.7/32
    !
    interface eth1
     no shutdown
     description p1 -> dut
     ip address 10.1.0.2/30
    !
    interface eth2
     no shutdown
     description p1 -> p2
     ip address 10.1.0.5/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [p2] => 
  msg: |-
    initial configuration for p2
    =========================================
    #!/bin/bash
    #
    set -e
    set -x
    #
    # Create bash profile script
    #
    cat <<SCRIPT >/root/.bash_profile
    #!/bin/bash
    #
    export PS1="\h(bash)#"
    echo "Use vtysh to connect to FRR daemon"
    echo
    SCRIPT
    #
    # Build hosts file
    #
    echo "# Created by netlab initial" >>/tmp/hosts
    echo "10.0.0.5 10.1.0.1 dut" >>/tmp/hosts
    echo "172.16.0.5 dut-t1" >>/tmp/hosts
    echo "172.16.2.5 dut-t2" >>/tmp/hosts
    echo "172.16.0.1 h1" >>/tmp/hosts
    echo "172.16.1.2 h2" >>/tmp/hosts
    echo "172.16.2.3 h3" >>/tmp/hosts
    echo "172.16.3.4 h4" >>/tmp/hosts
    echo "10.0.0.7 10.1.0.2 10.1.0.5 p1" >>/tmp/hosts
    echo "10.0.0.8 10.1.0.6 10.1.0.9 p2" >>/tmp/hosts
    echo "10.0.0.6 10.1.0.10 pe2" >>/tmp/hosts
    echo "172.16.1.6 pe2-t1" >>/tmp/hosts
    echo "172.16.3.6 pe2-t2" >>/tmp/hosts
    grep "Created by netlab" /etc/hosts || uniq /tmp/hosts|sort >>/etc/hosts
  
    #
    # Get the current next hop for the default route
    #
    def_nh=$(ip route list default|awk '{ print $3 }')
    #
    # Create the management VRF and add eth0 to it
    #
    if [ ! -e /sys/devices/virtual/net/mgmt ]; then
      ip link add mgmt type vrf table 42
    fi
    ip link set mgmt up
    sysctl -qw net.ipv6.conf.eth0.keep_addr_on_down=1
    ip link set eth0 master mgmt
    #
    # Reinstall the default route if we had it before
    #
    if [[ -n "$def_nh" ]]; then
      ip route add 0.0.0.0/0 vrf mgmt via $def_nh
    fi
    #
    # Enable FRR modules (if not using containerlab bind-mounted /etc/frr/daemons)
    #
  
    #
    # Create loopbacks and stub devices
    #
    if [ ! -e /sys/class/net/lo ]; then
      if [ ! -e /sys/devices/virtual/net/lo ]; then
        ip link add lo type dummy
        ip link set dev lo up
      fi
    fi
  
    # Disable IPv6 (for IPv4-only interfaces) or SLAAC (if the device is a router)
    #
    sysctl -qw net.ipv6.conf.eth1.disable_ipv6=1
    sysctl -qw net.ipv6.conf.eth2.disable_ipv6=1
  
    #
    # Add vtysh.conf file
    echo "service integrated-vtysh-config" >/etc/frr/vtysh.conf
    #
    # Set Ethernet interface MTU
    ip link set eth1 mtu 1500
    ip link set eth2 mtu 1500
    #
    # Rest of initial configuration done through VTYSH
    #
    cat >/tmp/config <<CONFIG
    hostname p2
    !
    vrf mgmt
     exit-vrf
    !
    frr defaults datacenter
    !
    interface lo
     no shutdown
     ip address 10.0.0.8/32
    !
    interface eth1
     no shutdown
     description p2 -> p1
     ip address 10.1.0.6/30
    !
    interface eth2
     no shutdown
     description p2 -> pe2
     ip address 10.1.0.9/30
    !
    do write
    CONFIG
    vtysh -f /tmp/config
    exit 0
ok: [h4] => 
  msg: |-
    initial configuration for h4
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.3.4/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.3.4/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.3.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.3.6
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.3.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.3.6
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.3.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.3.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.3.6
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.3.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.3.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.3.6
    #
    # Print the final routing table
    ip route
ok: [h3] => 
  msg: |-
    initial configuration for h3
    =========================================
    #!/bin/bash
    #
    # This script contains the 'ip' commands needed to set up container
    # interfaces and route table. It's executed within the container
    # network namespace on the container host.
    #
    #  /etc/hosts file is generated as a clab bind.
    #
    set -e
    ### One-Shot configuration (non-Ubuntu VM or container)
    #
    # Disable IPv4 and IPv6 forwarding
    #
    sysctl -w net.ipv4.ip_forward=0
    sysctl -w net.ipv6.conf.all.forwarding=0
    #
    # Interface addressing
    #
    ip link set dev eth1 up
    set +e
    ip addr del 172.16.2.3/24 dev eth1 2>/dev/null
    set -e
    ip addr add 172.16.2.3/24 dev eth1
    ip link set eth1 mtu 1500
    #
    # Add routes to IPv4 address pools pointing to the first neighbor on the first link
    #
    # If you need anything better, use FRR instead of Linux and start routing (or use IPv6)
    #
    # lan prefix: 172.16.0.0/16 local subnet: 172.16.2.0/24
    set +e
    ip route del 172.16.0.0/16 2>/dev/null
    set -e
    ip route add 172.16.0.0/16 via 172.16.2.5
    # loopback prefix: 10.0.0.0/24 local subnet: 172.16.2.0/24
    set +e
    ip route del 10.0.0.0/24 2>/dev/null
    set -e
    ip route add 10.0.0.0/24 via 172.16.2.5
    # mgmt prefix: 192.168.17.0/24 local subnet: 172.16.2.0/24
    # p2p prefix: 10.1.0.0/16 local subnet: 172.16.2.0/24
    set +e
    ip route del 10.1.0.0/16 2>/dev/null
    set -e
    ip route add 10.1.0.0/16 via 172.16.2.5
    # router_id prefix: 10.0.0.0/24 local subnet: 172.16.2.0/24
    # vrf_loopback prefix: 10.2.0.0/24 local subnet: 172.16.2.0/24
    set +e
    ip route del 10.2.0.0/24 2>/dev/null
    set -e
    ip route add 10.2.0.0/24 via 172.16.2.5
    #
    # Print the final routing table
    ip route

TASK [Find configuration deployment deploy_script for initial] *****************
ok: [pe2]
ok: [dut]
ok: [p1]
ok: [p2]
ok: [h1]
ok: [h4]
ok: [h3]
ok: [h2]

TASK [Deploy initial configuration] ********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/initial-clab.yml for pe2, p1, p2
included: /home/pipi/net101/tools/netsim/ansible/tasks/linux/initial-clab.yml for h1, h2, h3, h4

TASK [junos_config: deploying initial from /home/pipi/net101/tools/netsim/ansible/templates/initial/junos.j2] ***
changed: [dut]

TASK [Attempt to load VRF kernel module] ***************************************
changed: [pe2 -> localhost]
changed: [p1 -> localhost]
changed: [p2 -> localhost]

TASK [Disable FRR management VRF when modprobe fails] **************************
skipping: [pe2]
skipping: [p1]
skipping: [p2]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for pe2, p1, p2

TASK [template] ****************************************************************
changed: [p1]
changed: [pe2]
changed: [p2]

TASK [set_fact] ****************************************************************
ok: [pe2]
ok: [p1]
ok: [p2]

TASK [run /tmp/config.sh to deploy initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
changed: [pe2]
changed: [p1]
changed: [p2]

TASK [run vtysh to import initial config from /home/pipi/net101/tools/netsim/ansible/templates/initial/frr.j2] ***
skipping: [pe2]
skipping: [p1]
skipping: [p2]

TASK [set_fact] ****************************************************************
ok: [h1]
ok: [h2]
ok: [h3]
ok: [h4]

TASK [Create initial container setup from /home/pipi/net101/tools/netsim/ansible/templates/initial/linux-clab.j2] ***
changed: [h3 -> localhost]
changed: [h4 -> localhost]
changed: [h2 -> localhost]
changed: [h1 -> localhost]

TASK [Initial container configuration via /tmp/config-JUmhjEAq-h1.sh] **********
changed: [h2 -> localhost]
changed: [h1 -> localhost]
changed: [h3 -> localhost]
changed: [h4 -> localhost]

TASK [file] ********************************************************************
changed: [h1 -> localhost]
changed: [h4 -> localhost]
changed: [h3 -> localhost]
changed: [h2 -> localhost]

PLAY [Deploy module-specific configurations] ***********************************

TASK [Set variables that cannot be set with VARS] ******************************
ok: [p1]
ok: [p2]
ok: [pe2]
ok: [dut]

TASK [Deploy individual configuration modules] *********************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, p1, p2, pe2 => (item=bgp)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, p1, p2, pe2 => (item=ospf)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, p1, p2, pe2 => (item=mpls)
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-module.yml for dut, p1, p2, pe2 => (item=vrf)

TASK [Figure out whether to deploy the module bgp on current device] ***********
ok: [p1]
ok: [p2]
ok: [dut]
ok: [pe2]

TASK [Find configuration template for bgp] *************************************
skipping: [p1]
skipping: [p2]
ok: [dut]
ok: [pe2]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [p1]
skipping: [p2]
ok: [dut] => 
  msg: |-
    bgp configuration for dut
    =========================================
    routing-options {
      autonomous-system 65001;
      router-id 10.0.0.5
    }
    policy-options {
      delete: policy-statement ibgp-export;
      delete: policy-statement ebgp-export;
    }
    policy-options {
      policy-statement ibgp-export {
        term advertise {
          from {
            protocol direct;
            interface [ lo0.0 ];
          }
          then accept;
        }
        term next-hop-self {
          from {
            route-type external;
          }
          then {
            next-hop self;
          }
        }
      }
      policy-statement ebgp-export {
        term advertise {
          from {
            protocol direct;
            interface [ lo0.0 ];
          }
          then accept;
        }
      }
    }
    protocols {
      delete: bgp;
    }
    protocols {
      bgp {
        group ibgp-peers-ipv4 {
          type internal;
          export ibgp-export;
          advertise-inactive;
          local-address 10.0.0.5;
          neighbor 10.0.0.6 {
            description pe2;
          }
        }
        group ebgp-peers {
          export ebgp-export;
          advertise-inactive;
        }
      }
    }
ok: [pe2] => 
  msg: |-
    bgp configuration for pe2
    =========================================
    !
    router bgp 65001
      no bgp ebgp-requires-policy
      no bgp default ipv4-unicast
      bgp default show-hostname
      bgp default show-nexthop-hostname
  
      ! Consider AS paths of same length but with different AS as ECMP candidates
      bgp bestpath as-path multipath-relax
  
      bgp router-id 10.0.0.6
    !
      neighbor 10.0.0.5 remote-as 65001
      neighbor 10.0.0.5 description dut
      neighbor 10.0.0.5 update-source lo
    !
     address-family ipv4 unicast
    !
      network 10.0.0.6/32
    !
    !
    !
      neighbor 10.0.0.5 activate
      neighbor 10.0.0.5 next-hop-self
      no neighbor 10.0.0.5 send-community all
      neighbor 10.0.0.5 send-community standard
      neighbor 10.0.0.5 send-community large
      neighbor 10.0.0.5 send-community extended
    !
    !
    !
    do write

TASK [Find configuration deployment deploy_script for bgp] *********************
skipping: [p1]
skipping: [p2]
ok: [pe2]
ok: [dut]

TASK [Deploy bgp configuration] ************************************************
skipping: [p1]
skipping: [p2]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for pe2

TASK [junos_config: deploying bgp from /home/pipi/net101/tools/netsim/ansible/templates/bgp/junos.j2] ***
[WARNING]:  statement not found
changed: [dut]

TASK [template] ****************************************************************
changed: [pe2]

TASK [set_fact] ****************************************************************
ok: [pe2]

TASK [run /tmp/config.sh to deploy bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
skipping: [pe2]

TASK [run vtysh to import bgp config from /home/pipi/net101/tools/netsim/ansible/templates/bgp/frr.j2] ***
changed: [pe2]

TASK [Figure out whether to deploy the module ospf on current device] **********
ok: [p1]
ok: [p2]
ok: [pe2]
ok: [dut]

TASK [Find configuration template for ospf] ************************************
ok: [p2]
ok: [p1]
ok: [pe2]
ok: [dut]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [p1] => 
  msg: |-
    ospf configuration for p1
    =========================================
    !
    ! OSPFv2 FRR configuration
    !
    router ospf
     ospf router-id 10.0.0.7
     timers throttle spf 10 50 500
     timers throttle lsa all 100
     timers lsa min-arrival 100
    exit
    !
    interface lo
    !
     ip ospf area 0.0.0.0
    !
    interface eth1
    ! p1 -> dut
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
    interface eth2
    ! p1 -> p2
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
  
    !
    do write
ok: [p2] => 
  msg: |-
    ospf configuration for p2
    =========================================
    !
    ! OSPFv2 FRR configuration
    !
    router ospf
     ospf router-id 10.0.0.8
     timers throttle spf 10 50 500
     timers throttle lsa all 100
     timers lsa min-arrival 100
    exit
    !
    interface lo
    !
     ip ospf area 0.0.0.0
    !
    interface eth1
    ! p2 -> p1
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
    interface eth2
    ! p2 -> pe2
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
  
    !
    do write
ok: [dut] => 
  msg: |-
    ospf configuration for dut
    =========================================
    routing-options {
      router-id 10.0.0.5
    }
    protocols {
      delete: ospf;
    }
  
    protocols {
      ospf {
        area 0.0.0.0 {
          interface lo0.0 {
          }
        }
        area 0.0.0.0 {
          interface ge-0/0/0.0 {
            interface-type p2p;
          }
        }
      }
    }
ok: [pe2] => 
  msg: |-
    ospf configuration for pe2
    =========================================
    !
    ! OSPFv2 FRR configuration
    !
    router ospf
     ospf router-id 10.0.0.6
     timers throttle spf 10 50 500
     timers throttle lsa all 100
     timers lsa min-arrival 100
    exit
    !
    interface lo
    !
     ip ospf area 0.0.0.0
    !
    interface eth1
    ! pe2 -> p2
     ip ospf area 0.0.0.0
     ip ospf network point-to-point
    !
  
    !
    do write

TASK [Find configuration deployment deploy_script for ospf] ********************
ok: [p1]
ok: [p2]
ok: [pe2]
ok: [dut]

TASK [Deploy ospf configuration] ***********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for p1, p2, pe2

TASK [junos_config: deploying ospf from /home/pipi/net101/tools/netsim/ansible/templates/ospf/junos.j2] ***
changed: [dut]

TASK [template] ****************************************************************
changed: [p2]
changed: [p1]
changed: [pe2]

TASK [set_fact] ****************************************************************
ok: [p1]
ok: [p2]
ok: [pe2]

TASK [run /tmp/config.sh to deploy ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
skipping: [p1]
skipping: [p2]
skipping: [pe2]

TASK [run vtysh to import ospf config from /home/pipi/net101/tools/netsim/ansible/templates/ospf/frr.j2] ***
changed: [pe2]
changed: [p1]
changed: [p2]

TASK [Figure out whether to deploy the module mpls on current device] **********
ok: [p1]
ok: [p2]
ok: [pe2]
ok: [dut]

TASK [Find configuration template for mpls] ************************************
ok: [p1]
ok: [p2]
ok: [pe2]
ok: [dut]

TASK [Print deployed configuration when running in verbose mode] ***************
ok: [dut] => 
  msg: |-
    mpls configuration for dut
    =========================================
  
  
  
    interfaces {
      ge-0/0/0.0 {
        family mpls;
      }
    }
  
    protocols {
      mpls {
        traffic-engineering bgp-igp-both-ribs;
        interface ge-0/0/0.0;
      }
      ldp {
        interface ge-0/0/0.0;
      }
    }
  
  
    routing-instances {
      t1 {
        vrf-table-label;
      }
      t2 {
        vrf-table-label;
      }
    }
  
    protocols {
      bgp {
        group ibgp-peers-ipv4 {
          neighbor 10.0.0.6 {
            family inet-vpn {
              unicast;
            }
          }
        }
      }
    }
ok: [p1] => 
  msg: |-
    mpls configuration for p1
    =========================================
    #!/bin/bash
  
    set -e
  
    sysctl -w net.mpls.platform_labels=1048575
    sysctl -w net.mpls.conf.eth1.input=1
    sysctl -w net.mpls.conf.eth2.input=1
  
    cat >/tmp/config <<CONFIG
    !
    mpls ldp
      router-id 10.0.0.7
      dual-stack transport-connection prefer ipv4
      address-family ipv4
        discovery transport-address 10.0.0.7
        interface eth1
        exit
        interface eth2
        exit
      exit
      address-family ipv6
      exit
    !
    !
    do write
    CONFIG
    vtysh -f /tmp/config
  
    exit 0
ok: [p2] => 
  msg: |-
    mpls configuration for p2
    =========================================
    #!/bin/bash
  
    set -e
  
    sysctl -w net.mpls.platform_labels=1048575
    sysctl -w net.mpls.conf.eth1.input=1
    sysctl -w net.mpls.conf.eth2.input=1
  
    cat >/tmp/config <<CONFIG
    !
    mpls ldp
      router-id 10.0.0.8
      dual-stack transport-connection prefer ipv4
      address-family ipv4
        discovery transport-address 10.0.0.8
        interface eth1
        exit
        interface eth2
        exit
      exit
      address-family ipv6
      exit
    !
    !
    do write
    CONFIG
    vtysh -f /tmp/config
  
    exit 0
ok: [pe2] => 
  msg: |-
    mpls configuration for pe2
    =========================================
    #!/bin/bash
  
    set -e
  
    sysctl -w net.mpls.platform_labels=1048575
    sysctl -w net.mpls.conf.eth1.input=1
  
    cat >/tmp/config <<CONFIG
    !
    mpls ldp
      router-id 10.0.0.6
      dual-stack transport-connection prefer ipv4
      address-family ipv4
        discovery transport-address 10.0.0.6
        interface eth1
        exit
      exit
      address-family ipv6
      exit
    !
    !
    router bgp 65001
     address-family ipv4 vpn
    !
      neighbor 10.0.0.5 activate
      neighbor 10.0.0.5 send-community both
      neighbor 10.0.0.5 next-hop-self
  
    !
    do write
    CONFIG
    vtysh -f /tmp/config
  
    exit 0

TASK [Find configuration deployment deploy_script for mpls] ********************
ok: [p1]
ok: [pe2]
ok: [p2]
ok: [dut]

TASK [Deploy mpls configuration] ***********************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/mpls-clab.yml for p1, p2, pe2

TASK [junos_config: deploying mpls from /home/pipi/net101/tools/netsim/ansible/templates/mpls/junos.j2] ***
changed: [dut]

TASK [Load MPLS kernel modules] ************************************************
changed: [p1 -> localhost]

TASK [include_tasks] ***********************************************************
included: /home/pipi/net101/tools/netsim/ansible/tasks/frr/deploy-config.yml for p1, p2, pe2

TASK [template] ****************************************************************
changed: [p2]
changed: [p1]
changed: [pe2]

TASK [set_fact] ****************************************************************
ok: [p1]
ok: [p2]
ok: [pe2]

TASK [run /tmp/config.sh to deploy mpls config from /home/pipi/net101/tools/netsim/ansible/templates/mpls/frr.j2] ***
changed: [p2]
changed: [p1]
changed: [pe2]

TASK [run vtysh to import mpls config from /home/pipi/net101/tools/netsim/ansible/templates/mpls/frr.j2] ***
skipping: [p1]
skipping: [p2]
skipping: [pe2]

TASK [Figure out whether to deploy the module vrf on current device] ***********
ok: [p1]
ok: [p2]
ok: [pe2]
ok: [dut]

TASK [Find configuration template for vrf] *************************************
skipping: [p1]
skipping: [p2]
ok: [pe2]
ok: [dut]

TASK [Print deployed configuration when running in verbose mode] ***************
skipping: [p1]
skipping: [p2]
ok: [dut] => 
  msg: |-
    vrf configuration for dut
    =========================================
  
  
    policy-options {
  
      policy-statement vrf-t1-ibgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
        term next-hop-self {
          from {
            route-type external;
          }
          then {
            next-hop self;
          }
        }
      }
  
      policy-statement vrf-t1-ebgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
      }
  
  
      policy-statement vrf-t2-ibgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
        term next-hop-self {
          from {
            route-type external;
          }
          then {
            next-hop self;
          }
        }
      }
  
      policy-statement vrf-t2-ebgp-export {
        term redis_direct {
          from {
            protocol direct;
          }
          then accept;
        }
        term redis_ospf {
          from {
            protocol ospf;
          }
          then accept;
        }
        term redis_ospf3 {
          from {
            protocol ospf3;
          }
          then accept;
        }
      }
  
    }
  
  
    routing-instances {
  
      t1 {
        routing-options {
          autonomous-system 65001;
          router-id 10.0.0.5
        }
  
        protocols {
          bgp {
  
            group ebgp-peers {
              export vrf-t1-ebgp-export;
              advertise-inactive;
            }
          }
        }
      }
  
  
      t2 {
        routing-options {
          autonomous-system 65001;
          router-id 10.0.0.5
        }
  
        protocols {
          bgp {
  
            group ebgp-peers {
              export vrf-t2-ebgp-export;
              advertise-inactive;
            }
          }
        }
      }
  
    }
ok: [pe2] => 
  msg: |-
    vrf configuration for pe2
    =========================================
    #!/bin/bash
    #
    set -e # Exit immediately when any command fails
    #
  
    # Create VRF tables
    if [ ! -e /sys/devices/virtual/net/t1 ]; then
    ip link add t1 type vrf table 100
    fi
    ip link set t1 up
    if [ ! -e /sys/devices/virtual/net/t2 ]; then
    ip link add t2 type vrf table 101
    fi
    ip link set t2 up
  
    # Move interfaces and loopbacks to vrfs
    sysctl -qw net.ipv6.conf.eth2.keep_addr_on_down=1
    ip link set eth2 master t1
    sysctl -qw net.ipv6.conf.eth3.keep_addr_on_down=1
    ip link set eth3 master t2
  
    cat >/tmp/vrf_config <<CONFIG
    vrf t1
     exit-vrf
    vrf t2
     exit-vrf
    !
    router bgp 65001
    !
    !
    router bgp 65001 vrf t1
     no bgp ebgp-requires-policy
     no bgp default ipv4-unicast
     bgp router-id 10.0.0.6
     address-family ipv4 unicast
      redistribute connected
      label vpn export auto
      export vpn
      import vpn
      rd vpn export 65000:1
      rt vpn import 65000:1
      rt vpn export 65000:1
     exit-address-family
    !
    !
    router bgp 65001 vrf t2
     no bgp ebgp-requires-policy
     no bgp default ipv4-unicast
     bgp router-id 10.0.0.6
     address-family ipv4 unicast
      redistribute connected
      label vpn export auto
      export vpn
      import vpn
      rd vpn export 65000:2
      rt vpn import 65000:2
      rt vpn export 65000:2
     exit-address-family
    !
    !
    do write
    !
    CONFIG
    vtysh -f /tmp/vrf_config
    exit $?

TASK [Find configuration deployment deploy_script for vrf] *********************
skipping: [p1]
skipping: [p2]
ok: [pe2]
ok: [dut]

TASK [Deploy vrf configuration] ************************************************
skipping: [p1]
skipping: [p2]
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/junos.yml for dut
included: /home/pipi/net101/tools/netsim/ansible/tasks/deploy-config/frr.yml for pe2

TASK [junos_config: deploying vrf from /home/pipi/net101/tools/netsim/ansible/templates/vrf/junos.j2] ***
changed: [dut]

TASK [template] ****************************************************************
changed: [pe2]

TASK [set_fact] ****************************************************************
ok: [pe2]

TASK [run /tmp/config.sh to deploy vrf config from /home/pipi/net101/tools/netsim/ansible/templates/vrf/frr.j2] ***
changed: [pe2]

TASK [run vtysh to import vrf config from /home/pipi/net101/tools/netsim/ansible/templates/vrf/frr.j2] ***
skipping: [pe2]

PLAY [Deploy custom deployment templates] **************************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
dut                        : ok=44   changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
h1                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h2                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h3                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
h4                         : ok=12   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
p1                         : ok=38   changed=8    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
p2                         : ok=37   changed=7    unreachable=0    failed=0    skipped=13   rescued=0    ignored=0   
pe2                        : ok=51   changed=11   unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   

